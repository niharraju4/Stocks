{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e63fcd-8165-451d-a5b0-8f905767d037",
   "metadata": {},
   "outputs": [],
   "source": [
    "import alpaca_trade_api as alpaca\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "alpaca_api = alpaca.REST('PKU5LEIDZZV83Y5ENASI', 'nvzOwJpyvr73GTitTDyga0MkI2Qd6RsK4PmhItbu', api_version='v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f6f0bd0-df6b-40e4-9b3c-62ffda3bf3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of energy company tickers\n",
    "energy_tickers = ['XOM', 'CVX', 'COP', 'EOG', 'PXD', 'SLB', 'PSX', 'MPC', 'VLO', 'HES', 'OXY', 'BKR', 'FANG', 'DVN', 'HAL']\n",
    "\n",
    "# Set the time frame\n",
    "timeframe = \"30Min\"\n",
    "\n",
    "# Set the start and end dates for the data\n",
    "start_date = \"2022-01-01T00:00:00-00:00\"\n",
    "end_date = \"2023-01-01T00:00:00-00:00\"\n",
    "\n",
    "# Dictionary to store stock data for each ticker\n",
    "stock_data = {}\n",
    "\n",
    "# Loop through each ticker and retrieve the data\n",
    "for ticker in energy_tickers:\n",
    "    df = alpaca_api.get_bars(ticker, timeframe, start_date, end_date).df\n",
    "    df['SMA30'] = df['close'].rolling(window=30).mean()\n",
    "    stock_data[ticker] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cc2e4d0-1e1f-4bba-81c8-7f2d6b968558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for XOM:\n",
      "signal\n",
      " 0.0    4566\n",
      " 1.0    1392\n",
      "-1.0    1353\n",
      "Name: count, dtype: int64\n",
      "Value counts for CVX:\n",
      "signal\n",
      " 0.0    4229\n",
      " 1.0    1235\n",
      "-1.0    1188\n",
      "Name: count, dtype: int64\n",
      "Value counts for COP:\n",
      "signal\n",
      " 0.0    3784\n",
      " 1.0    1026\n",
      "-1.0     999\n",
      "Name: count, dtype: int64\n",
      "Value counts for EOG:\n",
      "signal\n",
      " 0.0    3105\n",
      " 1.0    1039\n",
      "-1.0    1035\n",
      "Name: count, dtype: int64\n",
      "Value counts for PXD:\n",
      "signal\n",
      " 0.0    4312\n",
      " 1.0     421\n",
      "-1.0     404\n",
      "Name: count, dtype: int64\n",
      "Value counts for SLB:\n",
      "signal\n",
      " 0.0    4244\n",
      " 1.0    1245\n",
      "-1.0    1215\n",
      "Name: count, dtype: int64\n",
      "Value counts for PSX:\n",
      "signal\n",
      " 0.0    3148\n",
      " 1.0    1008\n",
      "-1.0     981\n",
      "Name: count, dtype: int64\n",
      "Value counts for MPC:\n",
      "signal\n",
      " 0.0    2960\n",
      " 1.0    1046\n",
      "-1.0     974\n",
      "Name: count, dtype: int64\n",
      "Value counts for VLO:\n",
      "signal\n",
      " 0.0    4492\n",
      " 1.0     491\n",
      "-1.0     475\n",
      "Name: count, dtype: int64\n",
      "Value counts for HES:\n",
      "signal\n",
      " 0.0    2802\n",
      "-1.0     789\n",
      " 1.0     782\n",
      "Name: count, dtype: int64\n",
      "Value counts for OXY:\n",
      "signal\n",
      " 0.0    5516\n",
      " 1.0    1088\n",
      "-1.0    1071\n",
      "Name: count, dtype: int64\n",
      "Value counts for BKR:\n",
      "signal\n",
      " 0.0    4415\n",
      "-1.0     253\n",
      " 1.0     244\n",
      "Name: count, dtype: int64\n",
      "Value counts for FANG:\n",
      "signal\n",
      " 0.0    3365\n",
      " 1.0    1049\n",
      "-1.0    1040\n",
      "Name: count, dtype: int64\n",
      "Value counts for DVN:\n",
      "signal\n",
      " 0.0    4598\n",
      " 1.0    1159\n",
      "-1.0    1117\n",
      "Name: count, dtype: int64\n",
      "Value counts for HAL:\n",
      "signal\n",
      " 0.0    5130\n",
      " 1.0     583\n",
      "-1.0     563\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "lookahead = 5\n",
    "all_tickers_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and process the data\n",
    "for ticker in energy_tickers:\n",
    "    df = alpaca_api.get_bars(ticker, timeframe, start_date, end_date).df\n",
    "    df['SMA30'] = df['close'].rolling(window=30).mean()\n",
    "    df['closePct'] = df['close'].pct_change()\n",
    "    df['Tstat30'] = (df['close'] - df['SMA30']) / df['close'].rolling(window=30).std()\n",
    "    df = df.dropna()\n",
    "    df['Ticker'] = ticker  # Add a column for the ticker symbol\n",
    "    \n",
    "    # Copy the DataFrame and reset the index\n",
    "    dfCopy = df.copy()\n",
    "    dfCopy = dfCopy.reset_index()\n",
    "    dfCopy['signal'] = 0\n",
    "    UpsideBreakout = False\n",
    "    DownsideBreakout = False\n",
    "\n",
    "'''Here's a breakdown of what the signals represent:\n",
    "\n",
    "Upside Breakout (signal = 1): This signal is generated when the stock's price moves above its SMA30, indicating a potential upward trend or breakout. Traders might interpret this as a buy signal, expecting the price to continue rising.\n",
    "\n",
    "Downside Breakout (signal = -1): This signal is generated when the stock's price falls below its SMA30, indicating a potential downward trend or breakout. Traders might interpret this as a sell signal, expecting the price to continue falling.\n",
    "\n",
    "No Signal (signal = 0): This indicates that there is no significant breakout, and the stock's price is moving within the range of its SMA30.'''\n",
    "\n",
    "    \n",
    "    # Calculate signals\n",
    "    for index, row in dfCopy.iterrows():\n",
    "        if index < dfCopy['close'].idxmax() - lookahead:\n",
    "            for x in range(lookahead):\n",
    "                if x == 0:\n",
    "                    y = 0\n",
    "                else:\n",
    "                    y = x - 1\n",
    "\n",
    "                if dfCopy.loc[index + x, 'close'] > dfCopy.loc[index + x, 'SMA30'] and dfCopy.loc[index + y, 'close'] < dfCopy.loc[index + y, 'SMA30']:\n",
    "                    UpsideBreakout = True\n",
    "                    break\n",
    "\n",
    "                if dfCopy.loc[index + x, 'close'] < dfCopy.loc[index + x, 'SMA30'] and dfCopy.loc[index + y, 'close'] > dfCopy.loc[index + y, 'SMA30']:\n",
    "                    DownsideBreakout = True\n",
    "                    break\n",
    "\n",
    "        if UpsideBreakout:\n",
    "            for x in range(lookahead):\n",
    "                dfCopy.loc[index + x, 'signal'] = 1\n",
    "            UpsideBreakout = False\n",
    "\n",
    "        if DownsideBreakout:\n",
    "            for x in range(lookahead):\n",
    "                dfCopy.loc[index + x, 'signal'] = -1\n",
    "            DownsideBreakout = False\n",
    "\n",
    "    # Drop NaN values and create the target variable 'y'\n",
    "    dfCopy = dfCopy.dropna()\n",
    "    y = dfCopy['signal'].shift(-1)\n",
    "\n",
    "    # Review the value counts\n",
    "    print(f\"Value counts for {ticker}:\")\n",
    "    print(y.value_counts())\n",
    "\n",
    "    # Add the processed data to the combined DataFrame\n",
    "    all_tickers_data = pd.concat([all_tickers_data, dfCopy])\n",
    "\n",
    "# Save the combined data with signals to a CSV file\n",
    "all_tickers_data.to_csv('all_tickers_data_with_signals.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e98c2e0f-51f5-4c1b-aab6-8d381d364801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>SMA30</th>\n",
       "      <th>closePct</th>\n",
       "      <th>Tstat30</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-01-03 14:15:00+00:00</td>\n",
       "      <td>61.40</td>\n",
       "      <td>61.4000</td>\n",
       "      <td>61.300</td>\n",
       "      <td>20</td>\n",
       "      <td>61.30</td>\n",
       "      <td>336</td>\n",
       "      <td>61.377842</td>\n",
       "      <td>61.513763</td>\n",
       "      <td>-0.001301</td>\n",
       "      <td>-0.855590</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-03 14:20:00+00:00</td>\n",
       "      <td>61.44</td>\n",
       "      <td>61.4400</td>\n",
       "      <td>61.390</td>\n",
       "      <td>19</td>\n",
       "      <td>61.39</td>\n",
       "      <td>835</td>\n",
       "      <td>61.413647</td>\n",
       "      <td>61.511763</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>-0.537036</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-03 14:25:00+00:00</td>\n",
       "      <td>61.24</td>\n",
       "      <td>61.3800</td>\n",
       "      <td>61.220</td>\n",
       "      <td>87</td>\n",
       "      <td>61.38</td>\n",
       "      <td>4637</td>\n",
       "      <td>61.284827</td>\n",
       "      <td>61.502097</td>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-1.839776</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-03 14:30:00+00:00</td>\n",
       "      <td>61.66</td>\n",
       "      <td>61.6645</td>\n",
       "      <td>61.210</td>\n",
       "      <td>4017</td>\n",
       "      <td>61.24</td>\n",
       "      <td>851866</td>\n",
       "      <td>61.322385</td>\n",
       "      <td>61.510763</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>1.036820</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-03 14:35:00+00:00</td>\n",
       "      <td>61.99</td>\n",
       "      <td>62.0201</td>\n",
       "      <td>61.665</td>\n",
       "      <td>3777</td>\n",
       "      <td>61.67</td>\n",
       "      <td>567721</td>\n",
       "      <td>61.873681</td>\n",
       "      <td>61.522097</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>2.804482</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28091</th>\n",
       "      <td>2022-12-30 21:20:00+00:00</td>\n",
       "      <td>39.45</td>\n",
       "      <td>39.4500</td>\n",
       "      <td>39.200</td>\n",
       "      <td>2</td>\n",
       "      <td>39.20</td>\n",
       "      <td>5100</td>\n",
       "      <td>39.445098</td>\n",
       "      <td>39.122727</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.904676</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28092</th>\n",
       "      <td>2022-12-30 21:40:00+00:00</td>\n",
       "      <td>39.34</td>\n",
       "      <td>39.3400</td>\n",
       "      <td>39.340</td>\n",
       "      <td>2</td>\n",
       "      <td>39.34</td>\n",
       "      <td>479</td>\n",
       "      <td>39.341670</td>\n",
       "      <td>39.135227</td>\n",
       "      <td>-0.002788</td>\n",
       "      <td>1.179655</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28093</th>\n",
       "      <td>2022-12-30 21:45:00+00:00</td>\n",
       "      <td>39.45</td>\n",
       "      <td>39.4500</td>\n",
       "      <td>39.450</td>\n",
       "      <td>1</td>\n",
       "      <td>39.45</td>\n",
       "      <td>500</td>\n",
       "      <td>39.450000</td>\n",
       "      <td>39.153227</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>1.673062</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28094</th>\n",
       "      <td>2022-12-30 21:50:00+00:00</td>\n",
       "      <td>39.35</td>\n",
       "      <td>39.3500</td>\n",
       "      <td>39.350</td>\n",
       "      <td>4</td>\n",
       "      <td>39.35</td>\n",
       "      <td>113</td>\n",
       "      <td>39.350000</td>\n",
       "      <td>39.165893</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>1.037712</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28095</th>\n",
       "      <td>2022-12-30 22:30:00+00:00</td>\n",
       "      <td>39.35</td>\n",
       "      <td>39.3500</td>\n",
       "      <td>39.350</td>\n",
       "      <td>3</td>\n",
       "      <td>39.35</td>\n",
       "      <td>5023</td>\n",
       "      <td>39.350000</td>\n",
       "      <td>39.180893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976752</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408069 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp  close     high     low  trade_count   open  \\\n",
       "0     2022-01-03 14:15:00+00:00  61.40  61.4000  61.300           20  61.30   \n",
       "1     2022-01-03 14:20:00+00:00  61.44  61.4400  61.390           19  61.39   \n",
       "2     2022-01-03 14:25:00+00:00  61.24  61.3800  61.220           87  61.38   \n",
       "3     2022-01-03 14:30:00+00:00  61.66  61.6645  61.210         4017  61.24   \n",
       "4     2022-01-03 14:35:00+00:00  61.99  62.0201  61.665         3777  61.67   \n",
       "...                         ...    ...      ...     ...          ...    ...   \n",
       "28091 2022-12-30 21:20:00+00:00  39.45  39.4500  39.200            2  39.20   \n",
       "28092 2022-12-30 21:40:00+00:00  39.34  39.3400  39.340            2  39.34   \n",
       "28093 2022-12-30 21:45:00+00:00  39.45  39.4500  39.450            1  39.45   \n",
       "28094 2022-12-30 21:50:00+00:00  39.35  39.3500  39.350            4  39.35   \n",
       "28095 2022-12-30 22:30:00+00:00  39.35  39.3500  39.350            3  39.35   \n",
       "\n",
       "       volume       vwap      SMA30  closePct   Tstat30 Ticker  signal  \n",
       "0         336  61.377842  61.513763 -0.001301 -0.855590    XOM       1  \n",
       "1         835  61.413647  61.511763  0.000651 -0.537036    XOM       1  \n",
       "2        4637  61.284827  61.502097 -0.003255 -1.839776    XOM       1  \n",
       "3      851866  61.322385  61.510763  0.006858  1.036820    XOM       1  \n",
       "4      567721  61.873681  61.522097  0.005352  2.804482    XOM       1  \n",
       "...       ...        ...        ...       ...       ...    ...     ...  \n",
       "28091    5100  39.445098  39.122727  0.002541  1.904676    HAL       0  \n",
       "28092     479  39.341670  39.135227 -0.002788  1.179655    HAL       0  \n",
       "28093     500  39.450000  39.153227  0.002796  1.673062    HAL       0  \n",
       "28094     113  39.350000  39.165893 -0.002535  1.037712    HAL       0  \n",
       "28095    5023  39.350000  39.180893  0.000000  0.976752    HAL       0  \n",
       "\n",
       "[408069 rows x 13 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tickers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d52bd67-6887-4a67-8c8c-0b7b56d31384",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 106\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;66;03m# Train the SVM model\u001b[39;00m\n\u001b[0;32m    105\u001b[0m     model \u001b[38;5;241m=\u001b[39m svm\u001b[38;5;241m.\u001b[39mSVC(probability\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 106\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train)\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m    108\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_scaled)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:201\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    192\u001b[0m     X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    193\u001b[0m         X,\n\u001b[0;32m    194\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    198\u001b[0m         accept_large_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    199\u001b[0m     )\n\u001b[1;32m--> 201\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_targets(y)\n\u001b[0;32m    203\u001b[0m sample_weight \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\n\u001b[0;32m    204\u001b[0m     [] \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m sample_weight, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64\n\u001b[0;32m    205\u001b[0m )\n\u001b[0;32m    206\u001b[0m solver_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:749\u001b[0m, in \u001b[0;36mBaseSVC._validate_targets\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight_ \u001b[38;5;241m=\u001b[39m compute_class_weight(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight, classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, y\u001b[38;5;241m=\u001b[39my_)\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    750\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of classes has to be greater than one; got \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    751\u001b[0m         \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m    752\u001b[0m     )\n\u001b[0;32m    754\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\n\u001b[0;32m    756\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as alpaca\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "alpaca_api = alpaca.REST('PKU5LEIDZZV83Y5ENASI', 'nvzOwJpyvr73GTitTDyga0MkI2Qd6RsK4PmhItbu', api_version='v2')\n",
    "\n",
    "# List of energy company tickers\n",
    "energy_tickers = ['XOM', 'CVX', 'COP', 'EOG', 'PXD', 'SLB', 'PSX', 'MPC', 'VLO', 'HES', 'OXY', 'BKR', 'FANG', 'DVN', 'HAL']\n",
    "\n",
    "# Set the time frame\n",
    "timeframe = \"30Min\"\n",
    "\n",
    "# Set the start and end dates for the data\n",
    "start_date = \"2022-01-01T00:00:00-00:00\"\n",
    "end_date = \"2023-01-01T00:00:00-00:00\"\n",
    "\n",
    "lookahead = 5\n",
    "all_tickers_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each ticker and process the data\n",
    "for ticker in energy_tickers:\n",
    "    df = alpaca_api.get_bars(ticker, timeframe, start_date, end_date).df\n",
    "    df['SMA30'] = df['close'].rolling(window=30).mean()\n",
    "    df['closePct'] = df['close'].pct_change()\n",
    "    df['Tstat30'] = (df['close'] - df['SMA30']) / df['close'].rolling(window=30).std()\n",
    "    df = df.dropna()\n",
    "    df['Ticker'] = ticker  # Add a column for the ticker symbol\n",
    "    \n",
    "    # Copy the DataFrame and reset the index\n",
    "    dfCopy = df.copy()\n",
    "    dfCopy = dfCopy.reset_index()\n",
    "    dfCopy['timestamp'] = pd.to_datetime(dfCopy['timestamp'])\n",
    "    dfCopy.set_index('timestamp', inplace=True)\n",
    "    dfCopy['signal'] = 0\n",
    "    UpsideBreakout = False\n",
    "    DownsideBreakout = False\n",
    "\n",
    "    # Calculate signals\n",
    "    for index, row in dfCopy.iterrows():\n",
    "     if index < dfCopy.index.max() - pd.Timedelta(minutes=lookahead * 5):  # Assuming 5-minute intervals\n",
    "        for x in range(lookahead):\n",
    "            if x == 0:\n",
    "                y = 0\n",
    "            else:\n",
    "                y = x - 1\n",
    "\n",
    "            next_index = index + pd.Timedelta(minutes=x * 5)  # Adjust the time delta for the next index\n",
    "            prev_index = index + pd.Timedelta(minutes=y * 5)  # Adjust the time delta for the previous index\n",
    "\n",
    "            if next_index in dfCopy.index and prev_index in dfCopy.index:\n",
    "                if dfCopy.loc[next_index, 'close'] > dfCopy.loc[next_index, 'SMA30'] and dfCopy.loc[prev_index, 'close'] < dfCopy.loc[prev_index, 'SMA30']:\n",
    "                    UpsideBreakout = True\n",
    "                    break\n",
    "\n",
    "                if dfCopy.loc[next_index, 'close'] < dfCopy.loc[next_index, 'SMA30'] and dfCopy.loc[prev_index, 'close'] > dfCopy.loc[prev_index, 'SMA30']:\n",
    "                    DownsideBreakout = True\n",
    "                    break\n",
    "\n",
    "        if UpsideBreakout:\n",
    "            for x in range(lookahead):\n",
    "                dfCopy.loc[index + pd.Timedelta(minutes=x * 5), 'signal'] = 1\n",
    "            UpsideBreakout = False\n",
    "\n",
    "        if DownsideBreakout:\n",
    "            for x in range(lookahead):\n",
    "                dfCopy.loc[index + pd.Timedelta(minutes=x * 5), 'signal'] = -1\n",
    "            DownsideBreakout = False\n",
    "\n",
    "\n",
    "    # Prepare the data for training and testing\n",
    "    dfCopy = dfCopy.dropna()\n",
    "    y = dfCopy['signal'].shift(-1)\n",
    "    y.index = pd.to_datetime(y.index)  # Ensure y's index is a datetime index\n",
    "    X = dfCopy[['closePct', 'Tstat30']].dropna()\n",
    "\n",
    "    training_begin = X.index.min()\n",
    "    training_end = X.index.min() + DateOffset(months=60)\n",
    "\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    training_end = X.index.max() - DateOffset(months=2)  # Use a more appropriate end date, e.g., 2 months before the max date in X\n",
    "    X_test = X.loc[training_end:]\n",
    "    y_test = y.loc[training_end:]\n",
    "    # Scale the features\n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "# Drop NaN values from y_train and corresponding rows in X_train_scaled\n",
    "    nan_mask_train = ~y_train.isnull().values\n",
    "    X_train_scaled = X_train_scaled[nan_mask_train]\n",
    "    y_train = y_train.dropna()\n",
    "# Drop NaN values from y_test and corresponding rows in X_test_scaled\n",
    "    nan_mask_test = ~y_test.isnull().values\n",
    "    X_test_scaled = X_test_scaled[nan_mask_test]\n",
    "    y_test = y_test.dropna()\n",
    "# Train the SVM model\n",
    "    model = svm.SVC(probability=True)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "# Make predictions\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "# Generate classification report\n",
    "    print(f\"Classification report for {ticker}:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "# Add the processed data to the combined DataFrame\n",
    "    all_tickers_data = pd.concat([all_tickers_data, dfCopy])\n",
    "# Save the combined data with signals to a CSV file\n",
    "all_tickers_data.to_csv('all_tickers_data_with_signals.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f90d2c8-2692-445a-9aec-4839834b87bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>trade_count</th>\n",
       "      <th>open</th>\n",
       "      <th>volume</th>\n",
       "      <th>vwap</th>\n",
       "      <th>SMA30</th>\n",
       "      <th>closePct</th>\n",
       "      <th>Tstat30</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-01-03 14:15:00+00:00</th>\n",
       "      <td>61.40</td>\n",
       "      <td>61.4000</td>\n",
       "      <td>61.300</td>\n",
       "      <td>20.0</td>\n",
       "      <td>61.30</td>\n",
       "      <td>336.0</td>\n",
       "      <td>61.377842</td>\n",
       "      <td>61.513763</td>\n",
       "      <td>-0.001301</td>\n",
       "      <td>-0.855590</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03 14:20:00+00:00</th>\n",
       "      <td>61.44</td>\n",
       "      <td>61.4400</td>\n",
       "      <td>61.390</td>\n",
       "      <td>19.0</td>\n",
       "      <td>61.39</td>\n",
       "      <td>835.0</td>\n",
       "      <td>61.413647</td>\n",
       "      <td>61.511763</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>-0.537036</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03 14:25:00+00:00</th>\n",
       "      <td>61.24</td>\n",
       "      <td>61.3800</td>\n",
       "      <td>61.220</td>\n",
       "      <td>87.0</td>\n",
       "      <td>61.38</td>\n",
       "      <td>4637.0</td>\n",
       "      <td>61.284827</td>\n",
       "      <td>61.502097</td>\n",
       "      <td>-0.003255</td>\n",
       "      <td>-1.839776</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03 14:30:00+00:00</th>\n",
       "      <td>61.66</td>\n",
       "      <td>61.6645</td>\n",
       "      <td>61.210</td>\n",
       "      <td>4017.0</td>\n",
       "      <td>61.24</td>\n",
       "      <td>851866.0</td>\n",
       "      <td>61.322385</td>\n",
       "      <td>61.510763</td>\n",
       "      <td>0.006858</td>\n",
       "      <td>1.036820</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-03 14:35:00+00:00</th>\n",
       "      <td>61.99</td>\n",
       "      <td>62.0201</td>\n",
       "      <td>61.665</td>\n",
       "      <td>3777.0</td>\n",
       "      <td>61.67</td>\n",
       "      <td>567721.0</td>\n",
       "      <td>61.873681</td>\n",
       "      <td>61.522097</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>2.804482</td>\n",
       "      <td>XOM</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:20:00+00:00</th>\n",
       "      <td>39.45</td>\n",
       "      <td>39.4500</td>\n",
       "      <td>39.200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.20</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>39.445098</td>\n",
       "      <td>39.122727</td>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.904676</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:40:00+00:00</th>\n",
       "      <td>39.34</td>\n",
       "      <td>39.3400</td>\n",
       "      <td>39.340</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39.34</td>\n",
       "      <td>479.0</td>\n",
       "      <td>39.341670</td>\n",
       "      <td>39.135227</td>\n",
       "      <td>-0.002788</td>\n",
       "      <td>1.179655</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:45:00+00:00</th>\n",
       "      <td>39.45</td>\n",
       "      <td>39.4500</td>\n",
       "      <td>39.450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>39.45</td>\n",
       "      <td>500.0</td>\n",
       "      <td>39.450000</td>\n",
       "      <td>39.153227</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>1.673062</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:50:00+00:00</th>\n",
       "      <td>39.35</td>\n",
       "      <td>39.3500</td>\n",
       "      <td>39.350</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39.35</td>\n",
       "      <td>113.0</td>\n",
       "      <td>39.350000</td>\n",
       "      <td>39.165893</td>\n",
       "      <td>-0.002535</td>\n",
       "      <td>1.037712</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 22:30:00+00:00</th>\n",
       "      <td>39.35</td>\n",
       "      <td>39.3500</td>\n",
       "      <td>39.350</td>\n",
       "      <td>3.0</td>\n",
       "      <td>39.35</td>\n",
       "      <td>5023.0</td>\n",
       "      <td>39.350000</td>\n",
       "      <td>39.180893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976752</td>\n",
       "      <td>HAL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>408069 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           close     high     low  trade_count   open  \\\n",
       "timestamp                                                               \n",
       "2022-01-03 14:15:00+00:00  61.40  61.4000  61.300         20.0  61.30   \n",
       "2022-01-03 14:20:00+00:00  61.44  61.4400  61.390         19.0  61.39   \n",
       "2022-01-03 14:25:00+00:00  61.24  61.3800  61.220         87.0  61.38   \n",
       "2022-01-03 14:30:00+00:00  61.66  61.6645  61.210       4017.0  61.24   \n",
       "2022-01-03 14:35:00+00:00  61.99  62.0201  61.665       3777.0  61.67   \n",
       "...                          ...      ...     ...          ...    ...   \n",
       "2022-12-30 21:20:00+00:00  39.45  39.4500  39.200          2.0  39.20   \n",
       "2022-12-30 21:40:00+00:00  39.34  39.3400  39.340          2.0  39.34   \n",
       "2022-12-30 21:45:00+00:00  39.45  39.4500  39.450          1.0  39.45   \n",
       "2022-12-30 21:50:00+00:00  39.35  39.3500  39.350          4.0  39.35   \n",
       "2022-12-30 22:30:00+00:00  39.35  39.3500  39.350          3.0  39.35   \n",
       "\n",
       "                             volume       vwap      SMA30  closePct   Tstat30  \\\n",
       "timestamp                                                                       \n",
       "2022-01-03 14:15:00+00:00     336.0  61.377842  61.513763 -0.001301 -0.855590   \n",
       "2022-01-03 14:20:00+00:00     835.0  61.413647  61.511763  0.000651 -0.537036   \n",
       "2022-01-03 14:25:00+00:00    4637.0  61.284827  61.502097 -0.003255 -1.839776   \n",
       "2022-01-03 14:30:00+00:00  851866.0  61.322385  61.510763  0.006858  1.036820   \n",
       "2022-01-03 14:35:00+00:00  567721.0  61.873681  61.522097  0.005352  2.804482   \n",
       "...                             ...        ...        ...       ...       ...   \n",
       "2022-12-30 21:20:00+00:00    5100.0  39.445098  39.122727  0.002541  1.904676   \n",
       "2022-12-30 21:40:00+00:00     479.0  39.341670  39.135227 -0.002788  1.179655   \n",
       "2022-12-30 21:45:00+00:00     500.0  39.450000  39.153227  0.002796  1.673062   \n",
       "2022-12-30 21:50:00+00:00     113.0  39.350000  39.165893 -0.002535  1.037712   \n",
       "2022-12-30 22:30:00+00:00    5023.0  39.350000  39.180893  0.000000  0.976752   \n",
       "\n",
       "                          Ticker  signal  \n",
       "timestamp                                 \n",
       "2022-01-03 14:15:00+00:00    XOM     1.0  \n",
       "2022-01-03 14:20:00+00:00    XOM     1.0  \n",
       "2022-01-03 14:25:00+00:00    XOM     1.0  \n",
       "2022-01-03 14:30:00+00:00    XOM     1.0  \n",
       "2022-01-03 14:35:00+00:00    XOM     1.0  \n",
       "...                          ...     ...  \n",
       "2022-12-30 21:20:00+00:00    HAL     0.0  \n",
       "2022-12-30 21:40:00+00:00    HAL     0.0  \n",
       "2022-12-30 21:45:00+00:00    HAL     0.0  \n",
       "2022-12-30 21:50:00+00:00    HAL     0.0  \n",
       "2022-12-30 22:30:00+00:00    HAL     0.0  \n",
       "\n",
       "[408069 rows x 12 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tickers_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ef8503c-0941-4956-a8d9-1a1bf245c3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for XOM:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for CVX:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for COP:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for EOG:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for PXD:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for SLB:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for PSX:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for MPC:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for VLO:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for HES:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for OXY:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for BKR:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for FANG:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for DVN:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n",
      "Value counts for HAL:\n",
      "signal\n",
      " 0.0    15581\n",
      "-1.0     4431\n",
      " 1.0     4316\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for ticker in energy_tickers:\n",
    "    # Your existing code for processing the data goes here\n",
    "    \n",
    "    # Print the value counts for the current ticker\n",
    "    print(f\"Value counts for {ticker}:\")\n",
    "    print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f632c3-5bb2-41a4-abb9-004510e2b5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for XOM:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.43      0.08      0.13      1049\n",
      "         0.0       0.66      0.97      0.79      3573\n",
      "         1.0       0.50      0.11      0.18      1068\n",
      "\n",
      "    accuracy                           0.65      5690\n",
      "   macro avg       0.53      0.39      0.37      5690\n",
      "weighted avg       0.59      0.65      0.55      5690\n",
      "\n",
      "Classification report for CVX:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.37      0.10      0.16       822\n",
      "         0.0       0.69      0.96      0.80      3043\n",
      "         1.0       0.43      0.10      0.17       837\n",
      "\n",
      "    accuracy                           0.66      4702\n",
      "   macro avg       0.50      0.39      0.38      4702\n",
      "weighted avg       0.59      0.66      0.58      4702\n",
      "\n",
      "Classification report for COP:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.11      0.18       765\n",
      "         0.0       0.69      0.97      0.81      2837\n",
      "         1.0       0.48      0.11      0.18       721\n",
      "\n",
      "    accuracy                           0.68      4323\n",
      "   macro avg       0.55      0.40      0.39      4323\n",
      "weighted avg       0.62      0.68      0.59      4323\n",
      "\n",
      "Classification report for EOG:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.45      0.27      0.33       750\n",
      "         0.0       0.76      0.90      0.82      2431\n",
      "         1.0       0.48      0.39      0.43       758\n",
      "\n",
      "    accuracy                           0.68      3939\n",
      "   macro avg       0.56      0.52      0.53      3939\n",
      "weighted avg       0.65      0.68      0.65      3939\n",
      "\n",
      "Classification report for PXD:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.40      0.21      0.27       767\n",
      "         0.0       0.76      0.87      0.81      2487\n",
      "         1.0       0.41      0.40      0.41       774\n",
      "\n",
      "    accuracy                           0.66      4028\n",
      "   macro avg       0.52      0.50      0.50      4028\n",
      "weighted avg       0.62      0.66      0.63      4028\n",
      "\n",
      "Classification report for SLB:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.39      0.03      0.05       806\n",
      "         0.0       0.68      0.98      0.80      3062\n",
      "         1.0       0.44      0.07      0.12       770\n",
      "\n",
      "    accuracy                           0.67      4638\n",
      "   macro avg       0.50      0.36      0.33      4638\n",
      "weighted avg       0.59      0.67      0.56      4638\n",
      "\n",
      "Classification report for PSX:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.45      0.23      0.30       709\n",
      "         0.0       0.76      0.89      0.82      2457\n",
      "         1.0       0.41      0.37      0.38       690\n",
      "\n",
      "    accuracy                           0.67      3856\n",
      "   macro avg       0.54      0.49      0.50      3856\n",
      "weighted avg       0.64      0.67      0.65      3856\n",
      "\n",
      "Classification report for MPC:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.50      0.34      0.41       757\n",
      "         0.0       0.77      0.89      0.83      2401\n",
      "         1.0       0.44      0.35      0.39       695\n",
      "\n",
      "    accuracy                           0.69      3853\n",
      "   macro avg       0.57      0.53      0.54      3853\n",
      "weighted avg       0.66      0.69      0.66      3853\n",
      "\n",
      "Classification report for VLO:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.53      0.15      0.24       739\n",
      "         0.0       0.70      0.96      0.81      2615\n",
      "         1.0       0.49      0.17      0.25       683\n",
      "\n",
      "    accuracy                           0.68      4037\n",
      "   macro avg       0.57      0.43      0.43      4037\n",
      "weighted avg       0.63      0.68      0.61      4037\n",
      "\n",
      "Classification report for HES:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.24      0.30       664\n",
      "         0.0       0.78      0.87      0.82      2221\n",
      "         1.0       0.46      0.47      0.46       695\n",
      "\n",
      "    accuracy                           0.68      3580\n",
      "   macro avg       0.55      0.53      0.53      3580\n",
      "weighted avg       0.65      0.68      0.66      3580\n",
      "\n",
      "Classification report for OXY:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.47      0.12      0.19      1224\n",
      "         0.0       0.70      0.95      0.81      3955\n",
      "         1.0       0.45      0.26      0.33      1203\n",
      "\n",
      "    accuracy                           0.66      6382\n",
      "   macro avg       0.54      0.44      0.44      6382\n",
      "weighted avg       0.61      0.66      0.60      6382\n",
      "\n",
      "Classification report for BKR:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.46      0.26      0.33       654\n",
      "         0.0       0.78      0.92      0.84      2378\n",
      "         1.0       0.46      0.36      0.41       628\n",
      "\n",
      "    accuracy                           0.70      3660\n",
      "   macro avg       0.57      0.51      0.53      3660\n",
      "weighted avg       0.67      0.70      0.68      3660\n",
      "\n",
      "Classification report for FANG:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.42      0.11      0.17       794\n",
      "         0.0       0.65      0.96      0.78      2420\n",
      "         1.0       0.47      0.13      0.20       769\n",
      "\n",
      "    accuracy                           0.63      3983\n",
      "   macro avg       0.52      0.40      0.39      3983\n",
      "weighted avg       0.57      0.63      0.55      3983\n",
      "\n",
      "Classification report for DVN:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.44      0.07      0.12       930\n",
      "         0.0       0.70      0.97      0.82      3822\n",
      "         1.0       0.53      0.15      0.23       985\n",
      "\n",
      "    accuracy                           0.69      5737\n",
      "   macro avg       0.56      0.40      0.39      5737\n",
      "weighted avg       0.63      0.69      0.60      5737\n",
      "\n",
      "Classification report for HAL:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.41      0.10      0.16       704\n",
      "         0.0       0.73      0.96      0.83      3215\n",
      "         1.0       0.39      0.12      0.18       708\n",
      "\n",
      "    accuracy                           0.70      4627\n",
      "   macro avg       0.51      0.39      0.39      4627\n",
      "weighted avg       0.63      0.70      0.63      4627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as alpaca\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "alpaca_api = alpaca.REST('PKU5LEIDZZV83Y5ENASI', 'nvzOwJpyvr73GTitTDyga0MkI2Qd6RsK4PmhItbu', api_version='v2')\n",
    "\n",
    "# List of energy company tickers\n",
    "energy_tickers = ['XOM', 'CVX', 'COP', 'EOG', 'PXD', 'SLB', 'PSX', 'MPC', 'VLO', 'HES', 'OXY', 'BKR', 'FANG', 'DVN', 'HAL']\n",
    "\n",
    "# Set the time frame\n",
    "timeframe = \"5Min\"\n",
    "\n",
    "# Set the start and end dates for the data\n",
    "start_date = \"2022-01-01T00:00:00-00:00\"\n",
    "end_date = \"2023-01-01T00:00:00-00:00\"\n",
    "\n",
    "lookahead = 5\n",
    "all_tickers_data = pd.DataFrame()# Loop through each ticker and process the data\n",
    "for ticker in energy_tickers:\n",
    "    df = alpaca_api.get_bars(ticker, timeframe, start_date, end_date).df\n",
    "    df['SMA30'] = df['close'].rolling(window=30).mean()\n",
    "    df['closePct'] = df['close'].pct_change()\n",
    "    df['Tstat30'] = (df['close'] - df['SMA30']) / df['close'].rolling(window=30).std()\n",
    "    df = df.dropna()\n",
    "    df['Ticker'] = ticker  # Add a column for the ticker symbol\n",
    "    \n",
    "    # Copy the DataFrame and reset the index\n",
    "    dfCopy = df.copy()\n",
    "    dfCopy = dfCopy.reset_index()\n",
    "    dfCopy['timestamp'] = pd.to_datetime(dfCopy['timestamp'])\n",
    "    dfCopy.set_index('timestamp', inplace=True)\n",
    "    dfCopy['signal'] = 0\n",
    "    UpsideBreakout = False\n",
    "    DownsideBreakout = False\n",
    "\n",
    "    # Calculate signals\n",
    "    for index, row in dfCopy.iterrows():\n",
    "        if index < dfCopy.index.max() - pd.Timedelta(minutes=lookahead * 5):  # Assuming 5-minute intervals\n",
    "            for x in range(lookahead):\n",
    "                if x == 0:\n",
    "                    y = 0\n",
    "                else:\n",
    "                    y = x - 1\n",
    "\n",
    "                next_index = index + pd.Timedelta(minutes=x * 5)  # Adjust the time delta for the next index\n",
    "                prev_index = index + pd.Timedelta(minutes=y * 5)  # Adjust the time delta for the previous index\n",
    "\n",
    "                if next_index in dfCopy.index and prev_index in dfCopy.index:\n",
    "                    if dfCopy.loc[next_index, 'close'] > dfCopy.loc[next_index, 'SMA30'] and dfCopy.loc[prev_index, 'close'] < dfCopy.loc[prev_index, 'SMA30']:\n",
    "                        UpsideBreakout = True\n",
    "                        break\n",
    "\n",
    "                    if dfCopy.loc[next_index, 'close'] < dfCopy.loc[next_index, 'SMA30'] and dfCopy.loc[prev_index, 'close'] > dfCopy.loc[prev_index, 'SMA30']:\n",
    "                        DownsideBreakout = True\n",
    "                        break\n",
    "\n",
    "            if UpsideBreakout:\n",
    "                for x in range(lookahead):\n",
    "                    dfCopy.loc[index + pd.Timedelta(minutes=x * 5), 'signal'] = 1\n",
    "                UpsideBreakout = False\n",
    "\n",
    "            if DownsideBreakout:\n",
    "                for x in range(lookahead):\n",
    "                    dfCopy.loc[index + pd.Timedelta(minutes=x * 5), 'signal'] = -1\n",
    "                DownsideBreakout = False\n",
    "\n",
    "    # Add the ticker symbol column\n",
    "    dfCopy['Ticker'] = ticker\n",
    "\n",
    "    # Prepare the data for training and testing\n",
    "    dfCopy = dfCopy.dropna()\n",
    "    y = dfCopy['signal'].shift(-1)\n",
    "    y.index = pd.to_datetime(y.index)  # Ensure y's index is a datetime index\n",
    "    X = dfCopy[['closePct', 'Tstat30']].dropna()\n",
    "\n",
    "    training_begin = X.index.min()\n",
    "    training_end = X.index.min() + DateOffset(months=60)\n",
    "\n",
    "    X_train = X.loc[training_begin:training_end]\n",
    "    y_train = y.loc[training_begin:training_end]\n",
    "\n",
    "    training_end = X.index.max() - DateOffset(months=2)  # Use a more appropriate end date, e.g., 2 months before the max date in X\n",
    "    X_test = X.loc[training_end:]\n",
    "    y_test = y.loc[training_end:]\n",
    "    \n",
    "    # Scale the features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    # Drop NaN values from y_train and corresponding rows in X_train_scaled\n",
    "    nan_mask_train = ~y_train.isnull().values\n",
    "    X_train_scaled = X_train_scaled[nan_mask_train]\n",
    "    y_train = y_train.dropna()\n",
    "\n",
    "    # Drop NaN values from y_test and corresponding rows in X_test_scaled\n",
    "    nan_mask_test = ~y_test.isnull().values\n",
    "    X_test_scaled = X_test_scaled[nan_mask_test]\n",
    "    y_test = y_test.dropna()\n",
    "\n",
    "    # Train the SVM model\n",
    "    model = svm.SVC(probability=True)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test_scaled)\n",
    "\n",
    "    # Generate classification report\n",
    "    print(f\"Classification report for {ticker}:\")\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # Add the processed data to the combined DataFrame\n",
    "    all_tickers_data = pd.concat([all_tickers_data, dfCopy])\n",
    "\n",
    "# Save the combined data with signals to a CSV file\n",
    "all_tickers_data.to_csv('all_tickers_data_with_signals.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d52404a6-1d21-4e4e-9434-f54c11a32972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in y_test: [-1.  0.  1.]\n",
      "Unique values in y_train: [-1.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique values in y_test:\", np.unique(y_test))\n",
    "print(\"Unique values in y_train:\", np.unique(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "41f57d61-48a4-48d4-a1f8-51e00bf7d67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_binary = y_train.replace({-1: 0})\n",
    "y_test_binary = y_test.replace({-1: 0})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64f22233-c697-450d-8100-f97c94c90424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the SVM model\n",
    "model = svm.SVC(probability=True)\n",
    "model.fit(X_train_scaled, y_train_binary)\n",
    "\n",
    "# Get probabilities for the positive class\n",
    "y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate precision, recall, and thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_binary, y_probs)\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve for {ticker}')\n",
    "plt.show()\n",
    "\n",
    "# Find the threshold with the highest F1 score\n",
    "# Calculate F1 scores\n",
    "# Calculate F1 scores, avoiding division by zero\n",
    "f1_scores = np.zeros_like(precision)\n",
    "non_zero_mask = (precision + recall) > 0\n",
    "f1_scores[non_zero_mask] = 2 * (precision[non_zero_mask] * recall[non_zero_mask]) / (precision[non_zero_mask] + recall[non_zero_mask])\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "\n",
    "# Make predictions with the best threshold\n",
    "y_pred = (y_probs >= best_threshold).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4a528b3e-a2a7-4e1d-88dd-1804dd58d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the threshold with the highest F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3a03448-71a2-4890-8ae5-6cd05e1b994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Threshold: 0.17444351315560275\n",
      "Index of Maximum Precision: 4626\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Threshold:\", best_threshold)\n",
    "print(\"Index of Maximum Precision:\", np.argmax(precision))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd58cf3f-55d8-4b3e-a08a-055e403de951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.91      0.13      0.22      3919\n",
      "         1.0       0.16      0.93      0.28       708\n",
      "\n",
      "    accuracy                           0.25      4627\n",
      "   macro avg       0.54      0.53      0.25      4627\n",
      "weighted avg       0.80      0.25      0.23      4627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make predictions with the best threshold\n",
    "y_pred = (y_probs >= best_threshold).astype(int)\n",
    "\n",
    "# Generate the classification report\n",
    "svm_testing_report = classification_report(y_test_binary, y_pred)\n",
    "\n",
    "# Print the classification report\n",
    "print(svm_testing_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "78071c56-577c-457b-8df8-723b5052cacb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>closePct</th>\n",
       "      <th>Tstat30</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-10-31 11:10:00+00:00</th>\n",
       "      <td>-0.013066</td>\n",
       "      <td>-3.155444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31 11:25:00+00:00</th>\n",
       "      <td>0.002817</td>\n",
       "      <td>-2.106856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31 11:45:00+00:00</th>\n",
       "      <td>0.001404</td>\n",
       "      <td>-1.600762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31 11:50:00+00:00</th>\n",
       "      <td>0.001403</td>\n",
       "      <td>-1.164344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-10-31 12:00:00+00:00</th>\n",
       "      <td>-0.009524</td>\n",
       "      <td>-2.930284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:20:00+00:00</th>\n",
       "      <td>0.002541</td>\n",
       "      <td>1.904676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:40:00+00:00</th>\n",
       "      <td>-0.002788</td>\n",
       "      <td>1.179655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:45:00+00:00</th>\n",
       "      <td>0.002796</td>\n",
       "      <td>1.673062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 21:50:00+00:00</th>\n",
       "      <td>-0.002535</td>\n",
       "      <td>1.037712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30 22:30:00+00:00</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.976752</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4628 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           closePct   Tstat30\n",
       "timestamp                                    \n",
       "2022-10-31 11:10:00+00:00 -0.013066 -3.155444\n",
       "2022-10-31 11:25:00+00:00  0.002817 -2.106856\n",
       "2022-10-31 11:45:00+00:00  0.001404 -1.600762\n",
       "2022-10-31 11:50:00+00:00  0.001403 -1.164344\n",
       "2022-10-31 12:00:00+00:00 -0.009524 -2.930284\n",
       "...                             ...       ...\n",
       "2022-12-30 21:20:00+00:00  0.002541  1.904676\n",
       "2022-12-30 21:40:00+00:00 -0.002788  1.179655\n",
       "2022-12-30 21:45:00+00:00  0.002796  1.673062\n",
       "2022-12-30 21:50:00+00:00 -0.002535  1.037712\n",
       "2022-12-30 22:30:00+00:00  0.000000  0.976752\n",
       "\n",
       "[4628 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "946e5b90-de86-47d3-be3e-477e66e17da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.08      0.50      0.13      4627\n",
      "weighted avg       0.02      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.58      0.50      0.13      4627\n",
      "weighted avg       0.87      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.00      0.00      3919\n",
      "         1.0       0.15      1.00      0.27       708\n",
      "\n",
      "    accuracy                           0.15      4627\n",
      "   macro avg       0.58      0.50      0.13      4627\n",
      "weighted avg       0.87      0.15      0.04      4627\n",
      "\n",
      "Threshold: 0.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.44      0.01      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.65      0.50      0.46      4627\n",
      "weighted avg       0.79      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.43      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.64      0.50      0.46      4627\n",
      "weighted avg       0.78      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.60      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.72      0.50      0.46      4627\n",
      "weighted avg       0.81      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.75      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.80      0.50      0.46      4627\n",
      "weighted avg       0.83      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.23\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.24\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.27\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.28\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.32\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.33\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.34\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.36\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.37\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.41\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.42\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.67      0.00      0.01       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.76      0.50      0.46      4627\n",
      "weighted avg       0.82      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.43\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.50      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.67      0.50      0.46      4627\n",
      "weighted avg       0.79      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.44\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.45\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.46\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.47\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.48\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.49\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.51\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.52\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.53\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.55\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.56\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.57\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.58\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.59\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.62\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.64\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.66\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.67\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.68\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.69\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.71\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.72\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.73\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.74\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.75\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.76\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.79\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.82\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.84\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.86\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.87\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.88\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.89\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.91\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.92\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.93\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.95\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.96\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.97\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n",
      "Threshold: 0.99\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      1.00      0.92      3919\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.85      4627\n",
      "   macro avg       0.42      0.50      0.46      4627\n",
      "weighted avg       0.72      0.85      0.78      4627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get probabilities for the positive class\n",
    "y_probs = model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "\n",
    "# Iterate over thresholds from 0.01 to 0.99\n",
    "for x in range(1, 100, 1):\n",
    "    threshold = float(x) / 100\n",
    "    print(\"Threshold:\", threshold)\n",
    "    \n",
    "    # Make predictions based on the current threshold\n",
    "    y_pred = (y_probs >= threshold).astype(int)\n",
    "    \n",
    "    # Generate and print the classification report, setting zero_division to 0\n",
    "    svm_testing_report = classification_report(y_test_binary, y_pred, zero_division=0)\n",
    "    print(svm_testing_report)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78bc8ed9-37b7-432f-975a-48b762ac5ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Scatter plot for each ticker comparing with SPY\n",
    "for ticker in energy_tickers:\n",
    "    ticker_df = all_tickers_data[all_tickers_data['Ticker'] == ticker]\n",
    "    for i in range(30, 61, 5):  # Different periods (30, 35, ..., 60)\n",
    "        merged_df = pd.concat([ticker_df['closePct'], spy_df['SPY_close_pct']], axis=1, join='inner').dropna()\n",
    "        merged_df = merged_df.pct_change(i).dropna()\n",
    "\n",
    "        corr = merged_df['closePct'].corr(merged_df['SPY_close_pct'])\n",
    "        if abs(corr) >= 0.1:\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            plt.scatter(merged_df['closePct'], merged_df['SPY_close_pct'])\n",
    "            plt.title(f'Scatterplot: {ticker} vs SPY (Period: {i} days)')\n",
    "            plt.xlabel(f'{ticker} % Change')\n",
    "            plt.ylabel('SPY % Change')\n",
    "            plt.show()\n",
    "            print(f'Correlation between {ticker} and SPY over {i} days: {corr}\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
